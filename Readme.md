# The Brain Rap Project

![](/IMG_20190119_164738.jpg)

## Real-Time Neural Feedback

This project uses a modified HTC Vive headset built by [Neurable](http://neurable.com/), which includes an EEG brain-wave detecting system integrated into it. The raw data is then compounded into various mental states:

1. Stress
1. Calm
1. Attention
1. Fatigue
1. Overall Arousal. 

These state values are then fed into the virtual scene to influence a number of elements in the scene to provide feedback to the performance on stage.

![](/Image.png)

## Additional Work

See our [whitepaper](https://www.academia.edu/38184834/Rapsheet_Multilayer_Perceptron_Algorithm) for additional work completed during the hackathon.


